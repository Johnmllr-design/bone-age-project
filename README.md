 Model vs. Doctor's Assessment Comparison

Project Overview

In this project, I compare the results of a human doctor's de-identified assessment with the predictions of a machine learning model. The goal of this comparison is to evaluate how closely the model's predictions align with the doctor's assessments, enabling an understanding of the model’s performance in a real-world medical context.

Purpose
The primary objective is to automate the comparison process between the outputs of a medical professional and an AI model. This helps to identify any gaps in the model’s predictions and areas for improvement. By parsing and comparing both assessments in a structured text document, we can draw meaningful conclusions about the accuracy and reliability of the model’s predictions.

How It Works

Data Inputs:
Doctor's Assessment: This is a de-identified evaluation by a medical professional. It contains information related to a patient's age.

Model Prediction: This output is a DICOM file.

Processing:
The final comparison from parsing the DICOM file is saved in a .txt file, where each comparison result is documented. 
Files and Directory Structure



